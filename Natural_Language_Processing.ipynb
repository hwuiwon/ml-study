{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Natural Language Processing",
      "provenance": [],
      "authorship_tag": "ABX9TyPcI3Gn9sbmChf6Is+61vgS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hwuiwon/ML_study/blob/master/Natural_Language_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiAWuppeJRDx",
        "colab_type": "text"
      },
      "source": [
        "# **Required Frameworks & Packages**\n",
        "\n",
        "## **Framework**\n",
        "> **[Tensorflow](https://www.tensorflow.org/)**: Machine learning open source library<br>**[Keras](https://keras.io/)**: Python deep learning library<br>**[Gensim](https://radimrehurek.com/gensim/)**: Open-source library for unsupervised topic modeling and natural language processing<br>**[Scikit-learn](https://scikit-learn.org/)**: Python machine learning library\n",
        "## **Packages**\n",
        "> **[NLTK](https://www.nltk.org/)**: Natural Language Toolkit for symbolic and statistical natural language processing for **English**<br>**[KoNLPy](https://konlpy.org/en/latest/)**: Python package for natural language processing of the **Korean language**<br>**[JPype](https://pypi.org/project/JPype1/)**:Python module to provide full access to **Java** from within Python\n",
        "\n",
        "Reference: https://wikidocs.net/book/2155"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLEPjff9Pc40",
        "colab_type": "text"
      },
      "source": [
        "### **Run below to install**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1MhXO_cuPCic",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "!pip install tensorflow\n",
        "!pip install keras\n",
        "!pip install gensim\n",
        "!pip install scikit-learn\n",
        "\n",
        "!pip install nltk\n",
        "!pip install konlpy\n",
        "!pip install Jpype1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd43ElaGUT6y",
        "colab_type": "code",
        "outputId": "8c5fcdc1-e33b-406f-ec58-ecd2d575a663",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Bbr3LXeShz7",
        "colab_type": "text"
      },
      "source": [
        "# **Text Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoCzzAgrS6BZ",
        "colab_type": "text"
      },
      "source": [
        "## **Word Tokenization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oif-DpCQTuZN",
        "colab_type": "text"
      },
      "source": [
        "### **Using Packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yXZsCWNT5E3",
        "colab_type": "code",
        "outputId": "456c28f7-6cfe-4d1b-cf90-d17ec4e20148",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# 1. Don't seperate words that include hyphen\n",
        "# 2. Seperate by appostrophe\n",
        "\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "tokenizer=TreebankWordTokenizer()\n",
        "text=\"Starting a home-based restaurant may be an ideal. it doesn't have a food chain or restaurant of their own.\"\n",
        "print(tokenizer.tokenize(text))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Starting', 'a', 'home-based', 'restaurant', 'may', 'be', 'an', 'ideal.', 'it', 'does', \"n't\", 'have', 'a', 'food', 'chain', 'or', 'restaurant', 'of', 'their', 'own', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2Hkx7_QU9MS",
        "colab_type": "code",
        "outputId": "905517b1-6141-478f-f524-67e690f44cba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "print(text_to_word_sequence(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"don't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', 'mr', \"jone's\", 'orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2m48bi0VXxTi",
        "colab_type": "text"
      },
      "source": [
        "## **Sentence Tokenization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbTadi3FYInc",
        "colab_type": "text"
      },
      "source": [
        "### **Using Packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U6cBidfYKHa",
        "colab_type": "code",
        "outputId": "f3974fe0-9433-4f17-8771-8e5cd1e3c784",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "text=\"His barber kept his word. But keeping such a huge secret to himself was driving him crazy. Finally, the barber went up a mountain and almost to the edge of a cliff. He dug a hole in the midst of some reeds. He looked about, to mae sure no one was near.\"\n",
        "print(sent_tokenize(text))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['His barber kept his word.', 'But keeping such a huge secret to himself was driving him crazy.', 'Finally, the barber went up a mountain and almost to the edge of a cliff.', 'He dug a hole in the midst of some reeds.', 'He looked about, to mae sure no one was near.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEvc6mQ3YUYR",
        "colab_type": "text"
      },
      "source": [
        "#### **Case: Korean**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVKhTnMnYYgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Korean Sentence Splitter\n",
        "pip install kss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avpj7rLBYZwB",
        "colab_type": "code",
        "outputId": "9078e7f5-3ba3-47dc-dae7-9287d9db890f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "import kss\n",
        "text='인체 임상 1상에 2개월이 소요된다. 인체 투여하고 나서 임상 결과는 3~4주면 판단할 수 있다. 원래는 2개월 소요되는데 식약처와 규제기관과 상의할 예정이다. 임상 2상과 3상을 같이 할것이냐, 2상을 따로 하고 3상을 할 것이냐도 규제기관과 협의가 남아있다.'\n",
        "print(kss.split_sentences(text))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['인체 임상 1상에 2개월이 소요된다.', '인체 투여하고 나서 임상 결과는 3~4주면 판단할 수 있다.', '원래는 2개월 소요되는데 식약처와 규제기관과 상의할 예정이다.', '임상 2상과 3상을 같이 할것이냐, 2상을 따로 하고 3상을 할 것이냐도 규제기관과 협의가 남아있다.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCpTTEVhxPG_",
        "colab_type": "text"
      },
      "source": [
        "## **Part of speech Tagging**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZyaMMoIxTd_",
        "colab_type": "text"
      },
      "source": [
        "### **Using Packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyTDJtkvxu8V",
        "colab_type": "code",
        "outputId": "e64a730e-3b07-4de9-88f8-21866e2a7cdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2g418-Gxihe",
        "colab_type": "code",
        "outputId": "c7ceb79d-b244-4bcc-bd7e-17e25a097a30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "text=\"I am actively looking for Ph.D. students. and you are a Ph.D. student.\"\n",
        "x=word_tokenize(text)\n",
        "pos_tag(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('I', 'PRP'),\n",
              " ('am', 'VBP'),\n",
              " ('actively', 'RB'),\n",
              " ('looking', 'VBG'),\n",
              " ('for', 'IN'),\n",
              " ('Ph.D.', 'NNP'),\n",
              " ('students', 'NNS'),\n",
              " ('.', '.'),\n",
              " ('and', 'CC'),\n",
              " ('you', 'PRP'),\n",
              " ('are', 'VBP'),\n",
              " ('a', 'DT'),\n",
              " ('Ph.D.', 'NNP'),\n",
              " ('student', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLXLg1s2x7Q9",
        "colab_type": "text"
      },
      "source": [
        "**P.O.S Tags**: https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsfimLJ-yT71",
        "colab_type": "text"
      },
      "source": [
        "#### **Case: Korean**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3zvysmdye4f",
        "colab_type": "code",
        "outputId": "9fd5e8af-abfa-4c98-e236-35cc272fa590",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        }
      },
      "source": [
        "from konlpy.tag import Okt  \n",
        "okt=Okt()  \n",
        "print(okt.morphs(\"국가와 전세계 기여하기 위해 예방적 차원에서라도 끝까지 투자할 생각이다.\"))\n",
        "print(okt.pos(\"국가와 전세계 기여하기 위해 예방적 차원에서라도 끝까지 투자할 생각이다.\"))\n",
        "print(okt.nouns(\"국가와 전세계 기여하기 위해 예방적 차원에서라도 끝까지 투자할 생각이다.\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['국가', '와', '전세계', '기여', '하기', '위해', '예방', '적', '차원', '에서라도', '끝', '까지', '투자', '할', '생각', '이다', '.']\n",
            "[('국가', 'Noun'), ('와', 'Josa'), ('전세계', 'Noun'), ('기여', 'Noun'), ('하기', 'Verb'), ('위해', 'Noun'), ('예방', 'Noun'), ('적', 'Suffix'), ('차원', 'Noun'), ('에서라도', 'Josa'), ('끝', 'Noun'), ('까지', 'Josa'), ('투자', 'Noun'), ('할', 'Verb'), ('생각', 'Noun'), ('이다', 'Josa'), ('.', 'Punctuation')]\n",
            "['국가', '전세계', '기여', '위해', '예방', '차원', '끝', '투자', '생각']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cD-tNbMFyuX0",
        "colab_type": "text"
      },
      "source": [
        "Where\n",
        "> **okt.morphs(String)**: Extract morphemes<br>\n",
        "> **okt.pos(String)**: Tag part of speech<br>\n",
        "> **okt.nouns(String)**: Extract nouns"
      ]
    }
  ]
}